# 第一部分 介绍深度学习
深度学习的三部分：神经网络架构、学习目标、学习
在第三步学习中，需要寻找到最佳的功能函数。
从函数的角度去理解：第一步、构造一个函数集；第二步、定义函数的拟合度；第三步、选择最佳函数
# 关于训练深度神经网络的一些建议
损失函数
小批度梯度下降
激活函数
调整学习率

## 为防止过拟合
可以提前终止训练步骤
正则化：权重衰减，在权重之前乘以某一系数
删除节点：每层神经元在更新之前有p%的概率被去除掉；还可以将其理解成一种集成方法。（因为在使用小批度梯度下降时，因选择的节点不同，去除的神经元也就不一样）
合适的神经网络结构如（cnn, 属于第一步，选择合适的神经网络）
# 各种各样的神经网络
## 卷积神经网络（CNN)
为何cnn适用于图片:
图片的输入层节点庞大，在判断时（如判断鸟嘴），多个神经元都做了重复的工作（因为不确定鸟嘴在哪里），在cnn中只用一个神经元来判断。而且像素的缩小不影响cnn的处理，可以节省空间。
卷积的目标：1，特征维度小于整个图片。2，特征在多个图片中都出现。
最大池化的目标：将像素降低不影响目标。
卷积：将原始的数据进行通过滑窗进行分割，与设置好的特征进行匹配，返回匹配的程度，当一个样本与所有特征都匹配结束之后，就得到了一个数据对应的特征集合。
零补充：通过零补充的方式可以得到与分隔之前大小相同的数据。
最大池：在滑窗返回的特征中，按照规律将区域分隔，在某一区域中选取匹配程度最高的作为当前区域的匹配程度。
经过卷积和最大池之后得到了一个新的特征，通过不断重复上述步骤，将最后结果作为特征，拉成向量后，作为输入，加到神经网络中，即为cnn.

## 循环神经网络（RNN)
将隐藏层进行储存，可以作为输入层进行输入。

# 下一股浪潮
极深神经网络：是具有不同深度的神经网络的集成，
注意力模型：
加强学习
